---
layout: page
title: Automatiic
description: Python Package for automatic differentiation
img: assets/img/projects/autodiff.png
importance: 6
category: tech
---

**Authors**: Austin Nguyen, Emma Besier, Hainan Xiong, Lottie Zhuang

**Affiliation**: Harvard University John A. Paulson School of Engineering and Applied Sciences, Harvard Institute for Applied Computational Science (IACS)

**Summary**: Automatic differentiation (AD) is the process by which we can generate the derivatives of several functions.  Derivatives are central to many processes and applications, ranging from statistics and machine learning to computational problems in physics and biological sciences.  As a testament to its value, widely used machine learning libraries such as Tensorflow & PyTorch has implemented automatic differentiation as a core feature. 

**Motivation**: Automatic differentiation, and the packages that implement it, have played a transformative role in optimization, neural networks, computer vision, natural language processing, and probabilistic inference. In almost every way, automatic differentiation outperforms its alternatives: manual differentiation is time consuming and prone to error, numerical differentiation can be highly inaccurate due to round-off and truncation errors, and symbolic differentiation often results in complex expressions.


**Deliverables**:
<a href='https://pypi.org/project/automatiic/'>PyPi Package</a>, <a href='https://github.com/cs107-califour/cs107-FinalProject'>GitHub</a>, <a href='https://docs.google.com/presentation/d/1Lr5LjNdJWgkW9o1kQeuuRpRQ-NJCs4JVrUEs9jLVyQ4/edit?usp=sharing'>Presentation</a>


