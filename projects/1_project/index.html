<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ML for OOD Detection | Austin Nguyen</title> <meta name="author" content="Austin Nguyen"> <meta name="description" content="Pest Management with Wadhwani AI"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://austpicious.github.io/projects/1_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Austin </span>Nguyen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">ML for OOD Detection</h1> <p class="post-description">Pest Management with Wadhwani AI</p> </header> <article> <p><strong>Authors</strong>: Austin Nguyen, Erin Tomlinson, Eric Helmold, Aloysius Lim, Molly Liu</p> <p><strong>Affiliation</strong>: Harvard University John A. Paulson School of Engineering and Applied Sciences, Harvard Institute for Applied Computational Science (IACS), Wadhwani AI</p> <p><strong>Abstract</strong>: Our goal is to identify and implement one or more effective solutions to the problem of out-of-distribution (OOD) image detection in Wadhwani AI’s CottonAce pest management app, allowing it to reject errant images with minimal processing overhead. Our contributions to this work are an exploration of supervised, unsupervised, and self-supervised approaches for OOD detection. We explore convolutional autoencoders (CAEs) paired with latent dimensional analysis as our primary technique for OOD detection. We also find great potential in contrastive learning approaches to circumvent the need for costly annotation and handcrafted feature approaches which offer high interpretability and low computational costs.</p> <p><strong>Overview</strong> Launched by Wadhwani AI, CottonAce is a pest management mobile application that helps cotton farmers manage bollworm infestations in their fields. It uses an AI algorithm to identify and count bollworms in user-submitted photos and makes customized pesticide treatment recommendations based on what is found.</p> <p><strong>Problem</strong> Images submitted should follow the app’s guidelines (i.e., taken on clean white paper) to maximize the success of CottonAce in identifying and counting pests. However, a key problem is that users may submit errant images that deviate from the submission guidelines. This can lead to downstream models returning erroneous pest counts on inappropriate images and can result in user attrition. The goal of our analysis was to investigate machine learning models that can help with out-of-distribution (OOD) image detection in this setting.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align:center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/project_ood_detection_example_imgs-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/project_ood_detection_example_imgs-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/project_ood_detection_example_imgs-1400.webp"></source> <img src="/assets/img/projects/project_ood_detection_example_imgs.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" title="ID vs. OOD vs. EC" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1: Example of ID, EC, and OOD </div> <p><strong>Solution</strong> We explored multiple approaches focused on OOD detection with the goal of allowing the app to reject errant images with minimal overhead processing. Our recommendation is to use a model with handcrafted features because it displays competitive performance across all metrics and is small enough to be easily deployed on a mobile device. If the constraint of model size can be relaxed, a more complex modeling approach such as using a convolutional neural network (CNN) or a convolutional autoencoder (CAE) with whitened density is recommended as both of these techniques have demonstrated strong performance and have the capacity to generalize better to unseen OOD examples.</p> <p><strong>Highlights</strong></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/project_ood_detection_main_results-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/project_ood_detection_main_results-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/project_ood_detection_main_results-1400.webp"></source> <img src="/assets/img/projects/project_ood_detection_main_results.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Main results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2: Stoplight Chart of results across supervised and unsupervised techniques </div> <ul> <li>Supervised models (rows 1-3) demonstrate strong performance on specific types of OOD images, but unsupervised/semi-supervised models (rows 4-7) may generalize better.</li> <li>In supervised setting, handcrafted features can achieve comparable performance to CNN with dramatically reduced model size, making it highly preferable on mobile platforms.</li> <li>Image features learned by a CAE can be improved for anomaly detection tasks by applying a whitening transformation that increases the distance between in-distribution (ID) and OOD latent embeddings.</li> <li>Contrastive learning (CSI) achieves competitive results out-of-the-box; further exploration with hyperparameter tuning for this technique is warranted.</li> <li>Across all seven techniques, we observe very strong performance on identifying OOD images when tested on external datasets (Oxford Flowers and Stanford dogs).</li> </ul> <p><strong>Final Thoughts &amp; Next Steps</strong></p> <p>Several approaches have the potential to be successful for OOD detection for Wadhwani AI. Supervised techniques demonstrate strong performance on the set of OOD images observed in Wadhwani’s Open Data, but unsupervised and self-supervised techniques have the potential to generalize better on unseen OOD images. For example, contrastive learning (CSI) as a self-supervised approach produces results that are strong without much tuning.</p> <p>For future work, we advise training models with more data and better ID/OOD labels acquired via crowdsourcing to resolve edge cases, exploring generalization error on additional external datasets, and experimenting with the approach of applying a whitening transformation to the latent image representations obtained from a contrastive learning (CSI) model to combine the benefits of multiple approaches into one consolidated OOD detection model.</p> <p><strong>Deliverables</strong>: <a href="https://github.com/harvard-ac297r-wadhwani-ai-pm/ood-detection" rel="external nofollow noopener" target="_blank">GitHub</a> • <a href="/assets/pdf/projects_ood_detection_wadhwani_ai.pdf">Technical Report</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Austin Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>